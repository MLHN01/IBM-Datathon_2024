{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52b0180a-e29a-4fe5-a0a5-378cb35f2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7649d4c4-e9db-44c2-9eb7-fd27bb89768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset from a URL\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "housing_data = pd.read_csv(url)\n",
    "\n",
    "# Overview of the data (display the first 5 rows)\n",
    "print(housing_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e2c1a-1da0-4275-a7bd-ce38c8ad5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there are any missing values in the data\n",
    "print(housing_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57cc5d61-83e5-4bf4-881a-9307ea31ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "median_house_value    0\n",
      "ocean_proximity       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Selecting numerical columns\n",
    "numeric_columns = housing_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Replacing missing values with the median of the column\n",
    "housing_data[numeric_columns] = housing_data[numeric_columns].fillna(housing_data[numeric_columns].median())\n",
    "\n",
    "# Checking if there are still missing values after imputing\n",
    "print(housing_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642da564-7f89-4f79-85e4-47c832b4b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical features into numerical dummy variables\n",
    "housing_data = pd.get_dummies(housing_data, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e1136a-d3fe-4b9b-a0b7-c5406660b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the features (X) and the target variable (y)\n",
    "X = housing_data.drop(\"median_house_value\", axis=1)\n",
    "y = housing_data[\"median_house_value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a062bc-2504-4419-bef7-4c96c052e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4d0bc7-1c22-4a03-8060-201ded53a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the training and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df11ef9b-ebfc-45d3-bfcf-8b3b76513ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing RandomForestRegressor with 500 trees and parallelization\n",
    "model = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5945384d-4642-47b1-a06d-66f91bc5439b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training the model with the training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model with the training data\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81982a5f-dfe1-48d8-9ea6-8ed5e838b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2dc92-3e38-4c0d-986b-33a17ba23664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the model evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Root of the Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)  # Coefficient of Determination (R²)\n",
    "\n",
    "# Outputting the evaluation metrics\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865490d4-a8f5-4642-a5fb-f0c2b46923ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of actual vs predicted values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.2)\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(\"Actual vs Predicted Prices\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75277e-83dc-47a4-bf1e-b64cf8a11041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating and visualizing feature importance\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[-10:]  # The 10 most important features\n",
    "\n",
    "# Plot of feature importance\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [X.columns[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9592664-969a-4028-8cf4-c392a88660fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae5a49-54b5-4a6b-9578-38ca1ccca1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data 1: Proximity to the Bay (Bay Area)\n",
    "test_data_1 = pd.DataFrame({\n",
    "    'longitude': [-122.23],\n",
    "    'latitude': [37.88],\n",
    "    'housing_median_age': [40.0],\n",
    "    'total_rooms': [700.0],\n",
    "    'total_bedrooms': [150.0],\n",
    "    'population': [350.0],\n",
    "    'households': [120.0],\n",
    "    'median_income': [9.0],\n",
    "    'ocean_proximity_NEAR BAY': [1],\n",
    "    'ocean_proximity_INLAND': [0],\n",
    "    'ocean_proximity_<1H OCEAN': [0],\n",
    "    'ocean_proximity_ISLAND': [0]\n",
    "})\n",
    "\n",
    "# Test Data 2: Inland\n",
    "test_data_2 = pd.DataFrame({\n",
    "    'longitude': [-119.77],\n",
    "    'latitude': [36.73],\n",
    "    'housing_median_age': [20.0],\n",
    "    'total_rooms': [1200.0],\n",
    "    'total_bedrooms': [250.0],\n",
    "    'population': [800.0],\n",
    "    'households': [280.0],\n",
    "    'median_income': [3.5],\n",
    "    'ocean_proximity_NEAR BAY': [0],\n",
    "    'ocean_proximity_INLAND': [1],\n",
    "    'ocean_proximity_<1H OCEAN': [0],\n",
    "    'ocean_proximity_ISLAND': [0]\n",
    "})\n",
    "\n",
    "# Test Data 3: Less than 1 Hour to the Ocean (<1H OCEAN)\n",
    "test_data_3 = pd.DataFrame({\n",
    "    'longitude': [-118.35],\n",
    "    'latitude': [34.05],\n",
    "    'housing_median_age': [15.0],\n",
    "    'total_rooms': [1100.0],\n",
    "    'total_bedrooms': [230.0],\n",
    "    'population': [600.0],\n",
    "    'households': [220.0],\n",
    "    'median_income': [7.5],\n",
    "    'ocean_proximity_NEAR BAY': [0],\n",
    "    'ocean_proximity_INLAND': [0],\n",
    "    'ocean_proximity_<1H OCEAN': [1],\n",
    "    'ocean_proximity_ISLAND': [0]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a3f9d-c146-428e-acbd-04e0d831c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all test data\n",
    "test_data = pd.concat([test_data_1, test_data_2, test_data_3], ignore_index=True)\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65384251-99e1-4dc4-8544-321c0d2e3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring the number of columns matches\n",
    "test_data_processed = test_data.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Scaling the test data\n",
    "test_data_scaled = scaler.transform(test_data_processed)\n",
    "\n",
    "# Making predictions\n",
    "test_predictions = model.predict(test_data_scaled)\n",
    "\n",
    "# Outputting the predictions\n",
    "for i, pred in enumerate(test_predictions):\n",
    "    print(f\"Prediction for test case {i+1}: {pred:.2f} (House price in USD)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa6d5d-ba6b-41e9-85b1-99274d52f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hypothetical datasets for different income groups\n",
    "# All other features held constant to examine the effect of income\n",
    "test_income_values = np.linspace(1, 15, 50)  # Income ranging from $10,000 to $150,000\n",
    "\n",
    "# Example features that are kept constant\n",
    "constant_features = {\n",
    "    'longitude': [-122.23] * len(test_income_values),\n",
    "    'latitude': [37.88] * len(test_income_values),\n",
    "    'housing_median_age': [30] * len(test_income_values),\n",
    "    'total_rooms': [800] * len(test_income_values),\n",
    "    'total_bedrooms': [150] * len(test_income_values),\n",
    "    'population': [400] * len(test_income_values),\n",
    "    'households': [100] * len(test_income_values),\n",
    "    'ocean_proximity_NEAR BAY': [1] * len(test_income_values),\n",
    "    'ocean_proximity_INLAND': [0] * len(test_income_values),\n",
    "    'ocean_proximity_<1H OCEAN': [0] * len(test_income_values),\n",
    "    'ocean_proximity_ISLAND': [0] * len(test_income_values)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027d3d3-5a5b-4b76-9bbb-c3e12779cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the test data to match the columns of the training data\n",
    "# Columns missing in the test data will be filled with 0\n",
    "income_effect_df = income_effect_df.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Scaling new data \n",
    "income_effect_scaled = scaler.transform(income_effect_df)\n",
    "\n",
    "# Predictions based on the different income levels\n",
    "predicted_prices = model.predict(income_effect_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b2e99-6906-4d33-85b8-a7e2dea4341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of results: House price as a function of income\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test_income_values, predicted_prices, label='Predicted House Prices', color='b', lw=2)\n",
    "plt.xlabel('Median Income (in tens of thousands USD)')\n",
    "plt.ylabel('Predicted House Price (USD)')\n",
    "plt.title('Effect of Income on House Prices')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe1c55-aa38-4a23-a4fa-63f7135727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of income required for housing costs (house price)\n",
    "income_vs_price_ratio = predicted_prices / (test_income_values * 10000) \n",
    "\n",
    "# Plot House price to income ratio\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test_income_values, income_vs_price_ratio, label='House Price/Income Ratio', color='r', lw=2)\n",
    "plt.axhline(y=0.3, color='gray', linestyle='--', label='30% Threshold (Affordability Limit)')\n",
    "plt.xlabel('Median Income (in tens of thousands USD)')\n",
    "plt.ylabel('House Price/Income Ratio')\n",
    "plt.title('House Price to Income Ratio')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6f0bf-5fd6-4924-ba7b-e919b8d96f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying population size\n",
    "test_population_values = np.linspace(100, 2000, 50)\n",
    "\n",
    "# Creating a DataFrame with variable population and constant other features\n",
    "population_effect_df = pd.DataFrame({\n",
    "    'longitude': [-122.23] * len(test_population_values),\n",
    "    'latitude': [37.88] * len(test_population_values),\n",
    "    'housing_median_age': [30] * len(test_population_values),\n",
    "    'total_rooms': [800] * len(test_population_values),\n",
    "    'total_bedrooms': [150] * len(test_population_values),\n",
    "    'population': test_population_values,\n",
    "    'households': [100] * len(test_population_values),\n",
    "    'median_income': [5.0] * len(test_population_values),\n",
    "    'ocean_proximity_NEAR BAY': [0] * len(test_population_values),\n",
    "    'ocean_proximity_INLAND': [1] * len(test_population_values),\n",
    "    'ocean_proximity_<1H OCEAN': [0] * len(test_population_values),\n",
    "    'ocean_proximity_ISLAND': [0] * len(test_population_values)\n",
    "})\n",
    "\n",
    "# Adjusting the columns to match the training set\n",
    "population_effect_df = population_effect_df.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Scaling the population data\n",
    "population_effect_scaled = scaler.transform(population_effect_df)\n",
    "\n",
    "# Predictions for different population sizes\n",
    "predicted_population_prices = model.predict(population_effect_scaled)\n",
    "\n",
    "# Plot House prices based on population size\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test_population_values, predicted_population_prices, label='Predicted House Prices', color='m', lw=2)\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Predicted House Price (USD)')\n",
    "plt.title('Effect of Population on House Prices')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf1d90-1d1d-43cd-8cb7-55c12797f146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720bc3f-61d8-4d67-9362-3d328554b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how many records and columns are in the DataFrame\n",
    "print(f\"Number of records: {housing_data.shape[0]}\")\n",
    "print(f\"Number of columns: {housing_data.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef231823-e59a-4f05-a9b3-0e2a790b25e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
